# Reporte de Datos

Header

## 1. Resumen general de los datos

### ‚úîÔ∏è 1.1 N√∫mero total de observaciones
- Contar **89.000 im√°genes**.
- Contar **20 categor√≠as**.
- Verificar consistencia entre `labels.csv`, `sprites.npy` e im√°genes en carpeta.

### ‚úîÔ∏è 1.2 Variables presentes
Para im√°genes, estas ‚Äúvariables‚Äù son:
- Matriz de p√≠xeles: **16√ó16√ó3**
- Etiqueta (**entero 0‚Äì19**)
- Ruta del archivo (`path`)

### ‚úîÔ∏è 1.3 Tipos de variables
- **Variables num√©ricas:** valores RGB (0‚Äì255)
- **Variable categ√≥rica:** etiqueta
- **Variable de texto:** path

### ‚úîÔ∏è 1.4 Verificaci√≥n de faltantes
- Confirmar que no falten rutas en `labels.csv`.
- Revisar que no haya im√°genes da√±adas o corruptas.
- Validar que `sprites_labels.npy` coincide en dimensi√≥n con `sprites.npy`.

### ‚úîÔ∏è 1.5 Distribuci√≥n general de las im√°genes
- Mosaico aleatorio de **100‚Äì300 im√°genes**.
- Verificar tama√±o uniforme (16√ó16).
- Verificar distribuci√≥n de categor√≠as (‚âà4.470 por clase).

## 2. Resumen de calidad de los datos

### ‚úîÔ∏è 2.1 Presencia de valores faltantes
Reporte exacto de:
- Im√°genes sin entrada en CSV.
- Rutas inv√°lidas.
- Errores de lectura (PIL, OpenCV).

### ‚úîÔ∏è 2.2 Duplicados
- Detectar duplicados por hash (MD5 o perceptual hash).
- Reportar porcentaje de duplicados encontrados.

### ‚úîÔ∏è 2.3 Valores extremos o inconsistencias
Ejemplos de casos a detectar:
- Sprites completamente negros.
- Sprites completamente blancos.
- Sprites con ruido aleatorio.
- Sprites con demasiados colores (>50 √∫nicos).
- Sprites con muy pocos colores (<3 √∫nicos).

### ‚úîÔ∏è 2.4 Outliers visuales
- Mostrar ejemplos ‚Äúraros‚Äù.
- Justificar si se deben:
- Mantener
- Corregir
- Eliminar

### ‚úîÔ∏è 2.5 Acciones tomadas
- Redimensionamiento uniforme.
- Conversi√≥n a `float32`.
- Normalizaci√≥n (0‚Äì1 o ‚Äì1 a 1).
- Eliminaci√≥n de im√°genes corruptas (si aplica).
- Eliminaci√≥n de duplicados (si existen).

## 3. Variable objetivo

<!-- *(Adaptaci√≥n del concepto para modelos de difusi√≥n)*
En modelos generativos **la variable objetivo es la propia imagen**:
> x ~ p_data -->
Los script que a los que se hace referencia en cada uno de los item analizados se encuentran dentro de `.\scripts\eda`

### ‚úîÔ∏è 3.1 Explicar por qu√© la variable objetivo es la imagen
<!-- - No clasificamos.
- No predecimos.
- Buscamos **modelar la distribuci√≥n completa de los datos**. -->

Esta parte se analizo con ayuda del script `3_1_variable_objetivo.py`.

Anteriormente se observo la posibilidad de que cada una de las imagenes puede identificarse con un hash el cual se puede utilizar para determinar que imagenes se parecen entre si, con lo que se pudieron determinar conjuntos de imagenes parecidas entre si, por lo que queremos ver como es el comportamiento de la distribuci√≥n de intensidad tanto del conjunto original de imagenes como el de imagenes √∫nicas. Al final de la ejecuci√≥n podemos observar el histograma de la distribuci√≥n de cada conjunto, junto a una imagen muy probable dentro del conjunto y otra de ruido poco probable dentro del mismo.

Los graficos de densidades son muy similares entre si, siendo los valores de intensidad cercanos a cero los que acumulan la mayor parte de la densidad, dandonos a entender que en todas las imagenes el color negro o cercanos a este predomina sobre los dem√°s. Adem√°s, la simiitud entre los histogramas implica que apezar de quedarse √∫nicamente con las imagenes diferentes, la estructura probabilistica de la intensidad se mantiene entre los conjuntos. Esto nos permite mejorar los tiempos de procesamiento trabajando con el conjunto de imagenes √∫nicas, habiendo pasado de $84.000$ a $1.665$.

### ‚úîÔ∏è 3.2 Distribuci√≥n global de las im√°genes
<!-- - Histogramas promedio de colores.
- Distribuci√≥n de intensidades por canal RGB.
- Visualizaci√≥n del ‚Äúpromedio‚Äù por clase. -->

Como resultado de la ejecuci√≥n del script `3_2_distri_imagenes.py`, podemos concluir lo siguiente.

Los histogramas muestran que al utilizar las imagenes √∫nicas, hay una disminuci√≥n en la densidad de la intensidad representada por el negro, lo que es coherente con los resultados obtenidos en el caso anteior. Tambi√©n podemos ver que las imagenes promedio son similares para ambos conjuntos, ya que la disminuci√≥n se da en una zona de las imagenes donde domina el negro.

### ‚úîÔ∏è 3.3 Variabilidad intra-clase
<!-- - Mosaicos 5√ó5 por clase.
- Comparaci√≥n visual de ejemplos dentro de una misma categor√≠a. -->
Como resultado de la ejecuci√≥n del script `3_3_variable_interclase.py`, podemos concluir lo siguiente.

Con el fin de comprender  las caracteristicas visuales de algunas de las categorias se compara el contenidos de dos mosaicos de $5\times5$ para dos categorias ecogidas al azar. La falta de homogeneidad de los objetos observados dentro de cada uno de los mosaicos, dejan ver que hay algo de `lable noise` dentro de todas las categorias, aumentando la variabilidad intra clases en todas las categorias y exigiendo a futuro mayor capacidad por parte de los modelos que se vayan a implementar.

### ‚úîÔ∏è 3.4 Variabilidad global
<!-- - **PCA** sobre vectores flattenizados (16√ó16√ó3 ‚Üí 768 componentes).
- **t-SNE** para clusters naturales. -->

Como resultado de la ejecuci√≥n del script `3_4_variabilidad_global.py`, podemos concluir lo siguiente.

PCA nos permitir√° descomponer las im√°genes (vectores de 768 dimensiones) y entender qu√© dimensiones (o combinaciones de p√≠xeles) explican la mayor parte de la variaci√≥n en tu dataset de pixel art. Esto es crucial para la eficiencia, ya que, si el 99% de la varianza se explica con solo 50 componentes, podemos reducir dr√°sticamente la dimensionalidad para ciertos entrenamientos o an√°lisis posteriores. Por esta raz√≥n utilizaremos el criterio del umbral, identificando la cantidad de componentes en donde se tiene el 80% y el 90% de la varianza explicada, la ejecuci√≥n del script muestra la cantidad de componentes necesarias para cada porcentaje escogido.

## 4. Variables individuales

*(Adaptado a an√°lisis de im√°genes)*

### ‚úîÔ∏è 4.1 Canales RGB como variables
<!-- - Histograma por canal.
- Distribuci√≥n de valores RGB por clase.
- Estad√≠sticas descriptivas por canal. -->

Como resultado de la ejecuci√≥n del script `4_1_rgb_variable.py`, podemos concluir lo siguiente.

En la ejecuci√≥n de este script podemos ver los siguientes resultados en cuanto a medidas estadisticas

## üìä Estad√≠sticas Descriptivas Globales (Canales RGB)
Canal  Media  StdDev  Min   Q1  Mediana     Q3    Max
    R  64.96   79.15 0.00 1.00    17.00 128.00 255.00
    G  70.59   83.84 0.00 3.00    17.00 143.00 255.00
    B  76.80   86.86 0.00 4.00    24.00 158.00 255.00

Donde podemos ver todos los canales de color alcanzan la menor y mayor intensidad en algun momento, siendo esto respaldado por el hecho de la gran cantidad de areas o pixeles en negro que hay dentro de las imagenes, debido a esto tambi√©n podemos ver que las desviaciones estandar tienen valores bastante altos con respecto a las medias de intensidad en cada uno de los canales. Este script tiene la capacidad de almacenar los histogramas y medidas estadisticas obtenidas en una nueva carpeta de nombre `analisis_4_1_rgb` dentro del directorio de git principal.

### ‚úîÔ∏è 4.2 N√∫mero de colores por imagen
- Conteo de colores √∫nicos.
- Relaci√≥n entre n√∫mero de colores y etiqueta.
- Clasificaci√≥n por:
- Low palette
- Mid palette
- High palette

### ‚úîÔ∏è 4.3 Estructura espacial
- Verificar centrado del sprite.
- An√°lisis de espacio vac√≠o vs contenido.
- Heatmap de densidad de p√≠xeles por clase.

### ‚úîÔ∏è 4.4 Posibles transformaciones
- Normalizaci√≥n.
- Estandarizaci√≥n de paleta.
- Pixel-shuffle (opcional).
- Augmentations razonables:
- Flip horizontal
- Shift peque√±o
- Rotaci√≥n m√≠nima (<15¬∞)
- Jitter de color

### ‚úîÔ∏è 4.5 Relaci√≥n con etiqueta
- Mapas de calor por clase.
- Imagen promedio por clase.
- Modos de color por clase.

## 5. Ranking de variables

*(Justificaci√≥n metodol√≥gica adaptada)*

### 5.1 ‚Äî An√°lisis PCA del Dataset Pixel Art

Este an√°lisis utiliza PCA para evaluar cu√°nta informaci√≥n visual se puede comprimir sin p√©rdida significativa en las im√°genes del dataset (89400 sprites de 16√ó16√ó3). El objetivo es entender la estructura latente del dataset, la redundancia crom√°tica y la complejidad real de sus variaciones espaciales.

---

#### Variancia explicada

La matriz aplanada resultante tiene dimensi√≥n 768 por imagen. Al aplicar PCA, observamos c√≥mo la varianza total se acumula a medida que se agregan componentes principales:

- **PC1:** 12.13 % de la variabilidad total  
- **Primeras 10 componentes:** 46.88 %  
- **Primeras 20 componentes:** 59.59 %  
- **Primeras 30 componentes:** ~70 %  

La siguiente figura muestra la curva completa de varianza acumulada:

![Variance curve](../../reports/figures/eda/pca/variance_ratio.png)

La curva crece con fuerza en los primeros componentes y luego se aplana, lo que indica que gran parte de la informaci√≥n est√° concentrada en pocas direcciones latentes. Esto revela un dataset altamente estructurado, con patrones visuales consistentes y poca variabilidad ca√≥tica.

---

#### Reconstrucciones por n√∫mero de componentes

Para evaluar el poder reconstructivo del PCA, se reconstruy√≥ una imagen del dataset utilizando diferentes cantidades de componentes. Esto permite visualizar cu√°nta informaci√≥n se pierde al reducir dimensionalidad.

##### Reconstrucci√≥n con 10 componentes

El resultado conserva la forma general pero pierde detalle fino. Los colores se agrupan en bloques y la silueta es apenas perceptible:

![k10](../../reports/figures/eda/pca/reconstruction_k10.png)

##### Reconstrucci√≥n con 20 componentes

La forma, proporciones y colores principales se restauran con mayor precisi√≥n. Se observan contornos m√°s claros y sombras m√°s coherentes:

![k20](../../reports/figures/eda/pca/reconstruction_k20.png)

##### Reconstrucci√≥n con 30 componentes

A partir de 30 componentes, la reconstrucci√≥n es visualmente estable y muy cercana al original. El nivel de detalle recuperado es suficiente para preservar la identidad del sprite:

![k30](../../reports/figures/eda/pca/reconstruction_k30.png)

---

#### Interpretaci√≥n t√©cnica

El comportamiento del PCA revela varias caracter√≠sticas clave del dataset:

- **Alta compresibilidad:** Un subconjunto peque√±o de componentes explica m√°s del 50 % de la variaci√≥n visual.
- **Estructura visual consistente:** La similitud entre sprites (formas redondeadas, paletas suaves, simetr√≠a) reduce la necesidad de dimensiones adicionales.
- **Informaci√≥n dominada por patrones globales:** Los cambios importantes provienen de grandes bloques de color y no de texturas locales complejas.
- **Latent space compacto:** Para modelos generativos posteriores (CNN, autoencoders, diffusion) basta un espacio latente de baja dimensionalidad; no es necesario trabajar directamente con los 768 p√≠xeles originales.

---

#### Conclusi√≥n

El an√°lisis PCA demuestra que el dataset de pixel art es altamente estructurado y presenta redundancia visual significativa. Con solo 20‚Äì30 componentes ya es posible reconstruir im√°genes con fidelidad considerable. Esto indica que:

1. Los modelos de aprendizaje pueden entrenar r√°pidamente sobre este dominio.  
2. Es viable trabajar con representaciones latentes comprimidas.  
3. La estructura visual es lo suficientemente coherente como para permitir modelos condicionados por clase.

Este punto del an√°lisis confirma que el dataset es ideal para m√©todos generativos basados en representaciones compactas y controlables.


### 5.2 ‚Äî Importancia del Color en el Dataset Pixel Art

Este an√°lisis eval√∫a c√≥mo los canales de color (R, G, B) contribuyen a la variabilidad del dataset de pixel art. Se analiza su varianza global, su comportamiento por clase, su colorfulness perceptual y la cantidad de informaci√≥n que retiene cada uno mediante PCA. Este estudio es fundamental para comprender la estructura estil√≠stica del dataset y para orientar el dise√±o de modelos generativos condicionados por color.

---

#### Varianza global por canal

El an√°lisis de varianza global muestra cu√°nta variabilidad aporta cada canal a trav√©s de todo el dataset. Los valores obtenidos son:

- **R:** 0.1303  
- **G:** 0.1267  
- **B:** 0.1772  

El canal **B** emerge como el m√°s variable y, por tanto, el m√°s informativo. Esto sugiere que la mayor parte del contraste y cambio visual se encuentra en la dimensi√≥n azul del espacio RGB, probablemente debido al uso intensivo de tonos p√∫rpuras, rosados y sombreados fr√≠os caracter√≠sticos del dataset.

![Varianza global](../../reports/figures/eda/color/global_variance.png)

---

#### Varianza por clase

Al segmentar por clase, la variabilidad adquiere mayor significado:

- **Clase 3** presenta la mayor variaci√≥n en los tres canales.  
- **Clase 2** es la m√°s homog√©nea, lo que indica paletas m√°s restringidas.  
- En todas las clases, el canal **B sigue siendo dominante**, confirmando su rol estructural en el estilo visual.

Esto respalda la hip√≥tesis de que cada clase agrupa sprites provenientes de **diferentes fuentes o estilos art√≠sticos**.

![Varianza por clase](../../reports/figures/eda/color/variance_by_class.png)

---

#### Colorfulness por clase

La m√©trica de **Hasler & S√ºsstrunk** aproxima la percepci√≥n humana del color basado en contrastes RG y YB. Los promedios obtenidos:

- **Clase 1:** 0.3807 (la m√°s saturada)  
- **Clase 2:** 0.3051  
- **Clases 0, 3, 4:** entre 0.22 y 0.23  

La Clase 1 destaca como el estilo m√°s vibrante, mientras que las dem√°s se mantienen m√°s neutras o uniformes en saturaci√≥n.

![Colorfulness por clase](../../reports/figures/eda/color/colorfulness_by_class.png)

---

#### Importancia de los canales mediante PCA

Se aplica PCA por canal para medir cu√°nta varianza captura el primer componente principal (PC1) de cada uno:

- **R:** 0.1741  
- **G:** 0.1564  
- **B:** 0.1848  

Nuevamente, el canal **B** es el que m√°s informaci√≥n concentra, lo que coincide con todos los an√°lisis anteriores.

![PCA por canal](../../reports/figures/eda/color/pca_by_channel.png)

---

#### Ranking integrado de importancia crom√°tica

Combinando:

- Varianza global  
- Varianza explicada por PCA  

el puntaje final queda:

- **B:** 0.3620  
- **R:** 0.3044  
- **G:** 0.2831  

El orden es:

**B > R > G**

Esto confirma que el azul es el eje crom√°tico dominante del dataset.

---

#### Conclusiones

El an√°lisis del color revela:

1. El **canal azul (B)** es el que mayor informaci√≥n aporta en todos los niveles evaluados.  
2. Las clases muestran firmas crom√°ticas diferentes, lo que apunta a **diferencias estil√≠sticas entre las fuentes del pixel art**.  
3. La Clase 1 es la m√°s saturada y visualmente intensa; la Clase 3 es la m√°s variable; la Clase 2 es la m√°s uniforme.  
4. El color es un atributo altamente discriminativo en el dataset, lo que ser√° clave para modelos de clasificaci√≥n, generaci√≥n y condicionamiento.

La importancia estructural del color, especialmente del canal azul, sugiere que los modelos generativos pueden beneficiarse de arquitecturas que traten expl√≠citamente la informaci√≥n crom√°tica ‚Äîya sea mediante embeddings condicionados, espacios latentes separados o m√≥dulos para manejo de estilo.

---



### 5.3 ‚Äî Separabilidad entre clases

La separabilidad entre clases en un dataset visual como este determina qu√© tan ‚Äúobjetiva‚Äù es la etiqueta para un modelo. Aunque cada sprite tiene una resoluci√≥n m√≠nima (16√ó16√ó3), sus variaciones crom√°ticas, posicionales y tem√°ticas pueden generar un espacio continuo m√°s que uno discreto. Esta secci√≥n eval√∫a ese fen√≥meno desde la estructura visual, estad√≠sticas de color, embeddings reducidos y m√©todos no supervisados.

---

#### **Visualizaci√≥n directa por clase (mosaicos)**

Los mosaicos permiten observar la coherencia tem√°tica interna de cada etiqueta. Las clases humanoides mantienen proporciones y poses similares; las criaturas exhiben variaciones de color vibrante; frutas y vegetales presentan patrones redondeados; los √≠tems se distinguen por contornos geom√©tricos y simetr√≠as.

![Class 0](../../reports/figures/eda/class_separability/label_grid_class0.png)
![Class 1](../../reports/figures/eda/class_separability/label_grid_class1.png)
![Class 2](../../reports/figures/eda/class_separability/label_grid_class2.png)
![Class 3](../../reports/figures/eda/class_separability/label_grid_class3.png)
![Class 4](../../reports/figures/eda/class_separability/label_grid_class4.png)

---

#### **Im√°genes promedio por clase**

El promedio condensa las regiones crom√°ticas dominantes. Las clases humanoides (0 y 4) colapsan en siluetas sim√©tricas; las criaturas (1) muestran masas difusas y verdes/azules; √≠tems (3) generan formas circulares sin detalle; frutas (2) forman manchas c√°lidas, coherentes con su paleta.

![Mean 0](../../reports/figures/eda/class_separability/label_mean_class0.png)
![Mean 1](../../reports/figures/eda/class_separability/label_mean_class1.png)
![Mean 2](../../reports/figures/eda/class_separability/label_mean_class2.png)
![Mean 3](../../reports/figures/eda/class_separability/label_mean_class3.png)
![Mean 4](../../reports/figures/eda/class_separability/label_mean_class4.png)

---

#### **Colorimetr√≠a por clase**

Las medias RGB reflejan tendencias claras:

- Clases **2** (frutas) ‚Üí paletas c√°lidas y valores altos en rojo y verde.
- Clases **0/4** (humanos) ‚Üí colores neutros, dominancia marr√≥n/gris.
- Clase **1** (criaturas) ‚Üí saturaci√≥n elevada en verdes y azules.
- Clase **3** (√≠tems) ‚Üí dispersi√≥n alta debido a variabilidad tem√°tica.

Pese a esto, las desviaciones est√°ndar son amplias en todas las clases, anticipando una fuerte superposici√≥n en espacios de color puros.

---

#### **t-SNE: proyecci√≥n del espacio visual**

La proyecci√≥n t-SNE confirma la intuici√≥n: las clases no forman grupos compactos. Los puntos se mezclan formando un gradiente continuo donde todos los tipos de sprites coexisten sin fronteras n√≠tidas. Las clases s√≥lo se distinguen en zonas muy peque√±as del espacio.

![t-SNE](../../reports/figures/eda/class_separability/tsne_labels.png)

Esta estructura dispersa indica que **la etiqueta de clase no est√° codificada linealmente en los p√≠xeles**. Cualquier modelo que busque separar clases deber√° aprender rasgos altamente no lineales.

---

#### **Silhouette score**

El puntaje silhouette cuantifica la cohesi√≥n intraclase y separaci√≥n interclase.  
Los resultados son negativos tanto en el espacio crudo como en PCA-50:

![Silhouette](../../reports/figures/eda/class_separability/silhouette_scores.png)

Valores:
- Raw pixels: **‚Äì0.051**
- PCA-50: **‚Äì0.034**

Un valor negativo implica que las instancias est√°n m√°s cerca de otras clases que de la propia. En t√©rminos pr√°cticos: **el dataset no presenta clusters naturales para estas cinco etiquetas**.

---

#### **K-means (5 clusters)**

K-means se ejecut√≥ para `k=5` sin usar etiquetas. La matriz de confusi√≥n entre predicci√≥n de cluster y clase real confirma el solapamiento:

![K-means confusion](../../reports/figures/eda/class_separability/confusion_clusters.png)

Los clusters no corresponden a las clases originales. Algunas clases se dividen en varios clusters, y varios clusters contienen instancias m√∫ltiples de distintas etiquetas. Las m√©tricas no supervisadas lo ratifican:

- Adjusted Rand Index: **0.057**
- Normalized Mutual Information: **0.194**

Ambas cercanas a 0 ‚Üí **alineamiento casi aleatorio**.

---

### **Conclusi√≥n t√©cnica**

Este an√°lisis deja claro que las clases del dataset **no son separables de forma lineal ni semicompacta** en su espacio visual original. Aunque cada categor√≠a tiene coherencia est√©tica superficial, las estructuras internas se traslapan profundamente: poses similares, paletas similares, contornos redondeados, saturaci√≥n inconsistente.

En consecuencia:

1. **M√©todos no supervisados no recuperan la estructura real.**  
2. **Un modelo supervisado debe aprender rasgos altamente espec√≠ficos**: contornos, proporciones, siluetas y microtexturas.  
3. **La etiqueta no es trivial**: requiere redes convolucionales capaces de extraer invariancias espaciales.  
4. **La mezcla visual sugiere que la dificultad del dataset no est√° en la finura del arte sino en su similitud estructural.**

Este comportamiento explica por qu√© arquitecturas simples pueden fallar, mientras que modelos convolucionales moderados (o autoencoders previos) logran capturar las se√±ales necesarias.

## 6. Relaci√≥n entre variables explicativas y variable objetivo


- Ratio de p√≠xeles vac√≠os vs clase.

### 6.1 ‚Äî Clasificador Auxiliar CNN (Separabilidad Real entre Clases)

Este experimento entrena una CNN peque√±a para evaluar si las clases del dataset contienen un *signal visual fuerte*, es decir, si es posible distinguirlas a partir de sus patrones crom√°ticos y espaciales sin un modelo profundo.  
El objetivo no es obtener un modelo final, sino medir la **separabilidad visual real** del dataset.

---

### Resultados obtenidos

#### Precisi√≥n por √©poca

El modelo alcanza **‚âà100 % de accuracy en validaci√≥n** desde muy temprano, lo que indica que las clases poseen patrones visuales extremadamente consistentes.

![Accuracy](../../reports/figures/eda/aux_classifier/accuracy_curve.png)

---

#### P√©rdida por √©poca

La p√©rdida cae a casi cero en solo 1‚Äì2 √©pocas, reforzando el comportamiento de separabilidad fuerte entre clases.

![Loss](../../reports/figures/eda/aux_classifier/loss_curve.png)

- **Loss final:** 0.00007  
- **Accuracy final:** 100 %  

---

### Matriz de confusi√≥n

La CNN clasifica *todas* las im√°genes de validaci√≥n correctamente.  
La matriz es diagonal perfecta:

![Confusion matrix](../../reports/figures/eda/aux_classifier/confusion_matrix.png)

Esto solo ocurre cuando los clusters visuales est√°n extremadamente bien definidos.

---

### Interpretaci√≥n t√©cnica

Los resultados permiten extraer varias conclusiones clave:

#### **1. Separabilidad absoluta**
Una CNN m√≠nima identifica cada clase con precisi√≥n perfecta.  
Esto sugiere que:

- dentro de cada clase hay **muy baja variabilidad**,  
- entre clases hay **diferencias visuales claras y robustas**.

#### **2. Las etiquetas no son aleatorias**
El modelo no podr√≠a converger as√≠ si las labels fueran ruido.  
Las clases parecen representar:

- estilos visuales,
- fuentes gr√°ficas diferentes,
- pipelines/artistas distintos,
- o familias de sprites con estructuras muy similares.

#### **3. Es viable un modelo condicionado por clase**
Dado el comportamiento perfecto:

- los modelos generativos pueden usar conditioning estable,
- se pueden generar estilos diferenciados f√°cilmente,
- no habr√° mezclas espurias entre clases.

---

### Conclusi√≥n

Este an√°lisis confirma que:

1. Las clases poseen **identidad visual fuerte**.  
2. El dataset es **limpio, estructurado y altamente separable**.  
3. La arquitectura del modelo generativo puede incorporar conditioning por clase sin riesgo.  

El clasificador auxiliar funciona como evidencia emp√≠rica de que la estructura latente observada en PCA, an√°lisis de color, t-SNE y UMAP tambi√©n se refleja en un modelo discriminativo simple.

---

