# Pixel Art Diffusion Project

Este repositorio contiene el pipeline completo para construir un modelo generativo basado en *diffusion*, utilizando un dataset de 89.400 imÃ¡genes de pixel art (16Ã—16Ã—3). El proyecto implementa un ciclo profesional de ciencia de datos con:

- **DVC** para manejo de datos, cachÃ© y versiones del pipeline.
- **EDA profunda** (PCA, t-SNE, anÃ¡lisis cromÃ¡tico, separabilidad de clases, CNN auxiliar).
- **Scripts modulares** para lectura, limpieza, procesado y anÃ¡lisis.
- **Estructura robusta de carpetas** siguiendo el estÃ¡ndar de proyectos ML reproducibles.

---

## ğŸš€ Objetivo del Proyecto

Construir un *modelo de difusiÃ³n* capaz de generar pixel art coherente, limpio y controlable por clase.  
El dataset original contiene ruido, duplicados y variaciones estilÃ­sticas; por eso se diseÃ±Ã³ un pipeline de EDA + procesamiento que permite:

- Detectar duplicados y quedarse con imÃ¡genes Ãºnicas.  
- Limpieza y normalizaciÃ³n del dataset.
- EvaluaciÃ³n de separabilidad real entre clases.
- ExploraciÃ³n de la estructura latente del dominio visual.

Todas las fases estÃ¡n versionadas con **DVC** para garantizar reproducibilidad y trazabilidad.

---

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Datos originales sin procesar
â”‚   â”œâ”€â”€ intermediate/      # Resultados generados por scripts (versionados con DVC)
â”‚   â””â”€â”€ processed/         # Conjunto final para entrenamiento de la difusiÃ³n
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ eda/               # AnÃ¡lisis exploratorio modular (3.x, 5.x, 6.x)
â”‚   â”œâ”€â”€ processing/        # Limpieza, normalizaciÃ³n, hashing, uniques
â”‚   â””â”€â”€ run_eda.py         # Orquestador unificado del EDA
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/           # GrÃ¡ficas generadas por todos los anÃ¡lisis
â”‚   â””â”€â”€ eda/               # Archivos de texto y JSON con resultados
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ data_summary.md    # Reporte completo del EDA
â”‚   â””â”€â”€ methodology.md     # DiseÃ±o metodolÃ³gico del proyecto
â”‚
â”œâ”€â”€ dvc.yaml               # Pipeline declarativo
â”œâ”€â”€ dvc.lock               # Trazabilidad exacta del experimento
â”œâ”€â”€ README.md              # Documento actual
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Scripts Clave

### `scripts/run_eda.py`
Orquestador general del EDA.  
Ejecuta:

- 3.1 â€“ Variable objetivo  
- 3.2 â€“ DistribuciÃ³n de imÃ¡genes  
- 3.3 â€“ Variabilidad intra-clase  
- 3.4 â€“ Variabilidad global  
- 5.1 â€“ PCA  
- 5.2 â€“ Importancia del color  
- 5.3 â€“ Separabilidad entre clases  
- 6.3 â€“ CNN auxiliar

Los resultados se guardan en:

```
reports/eda/eda.json
reports/figures/eda/
```

---

## ğŸ“¦ Uso del Proyecto

### 1. Clonar el repo
```
git clone https://github.com/usuario/pixel-art-diffusion.git
cd pixel-art-diffusion
```

### 2. Instalar dependencias
```
pip install -r requirements.txt
```

### 3. Descargar los datos con DVC
```
dvc pull
```

### 4. Ejecutar el EDA completo
```
python scripts/run_eda.py
```

### 5. Regenerar datos procesados
```
dvc repro
```

---

## ğŸ“Š Resultados principales

- El dataset tiene **altÃ­sima redundancia**, reduciendo ~89.400 â†’ 1.665 imÃ¡genes Ãºnicas.
- La distribuciÃ³n de intensidad se mantiene entre dataset completo y Ãºnico.
- PCA revela que **20â€“30 componentes** capturan la mayor parte de la estructura.
- El canal azul **B** es el eje cromÃ¡tico dominante.
- t-SNE y metrics no supervisadas muestran baja separabilidad lineal.
- Una **CNN auxiliar logra 100% accuracy**, evidenciando separabilidad profunda no lineal.

Todos los grÃ¡ficos estÃ¡n disponibles en:

```
reports/figures/eda/
```

---

## â˜ï¸ DVC y flujo de datos

El pipeline controla:

- Descarga de imÃ¡genes crudas.
- Limpieza y hashing.
- GeneraciÃ³n de dataset procesado `.npz`.
- EDA completo con sus salidas.

Modificar cualquier script hace que DVC regenere automÃ¡ticamente la etapa afectada.

Esto garantiza:

- **Reproducibilidad**
- **Trazabilidad**
- **Versionado de datasets y grÃ¡ficas**
- **EjecuciÃ³n consistente entre integrantes del equipo**

---

## ğŸ¤ Equipo

Proyecto desarrollado por:

- **David Paloma**
- **Juan Ayala**
- **Daniel Gracia**

Bajo la metodologÃ­a TDSP aplicada al desarrollo de modelos generativos.

---

## ğŸ“Œ Estado del Proyecto

âœ”ï¸ EDA finalizado  
âœ”ï¸ Pipeline limpio  
âœ”ï¸ Dataset procesado  
â¬œ Entrenamiento del modelo de difusiÃ³n  
â¬œ EvaluaciÃ³n y benchmarks  
â¬œ GeneraciÃ³n de experimentos condicionados

---

## ğŸ”® PrÃ³ximos pasos

1. ConstrucciÃ³n de la U-Net para difusiÃ³n.  
2. Entrenamiento con conditioning por clase.  
3. EvaluaciÃ³n de FID, IS y mÃ©tricas perceptuales.  
4. ImplementaciÃ³n de GUI minimal para generar sprites.

---

## ğŸ“„ Licencia

MIT â€” uso libre para investigaciÃ³n y desarrollo.
