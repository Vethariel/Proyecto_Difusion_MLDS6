{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "XCsPjXnb86F0",
        "outputId": "147eaab2-c343-4c13-8292-a2a6c5e5ccb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cargado: (89400, 16, 16, 3)\n",
            "=== INICIANDO EXPERIMENTO 5: ABLACIÓN ===\n",
            "\n",
            "--- VARIANTE A: Barrido de T ---\n",
            "\n",
            ">>> INICIANDO RUN: DDPM_T50_C32 (Epochs=15)\n",
            "WARNING:tensorflow:From d:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\.env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "   [Ep 1/15] Loss: 0.45128\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# EXPERIMENTO 5 — ABLACIÓN: RUIDO (T) & CAPACIDAD (Pixel-Space DDPM)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, optimizers\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ============================================================\n",
        "# 1. CONFIGURACIÓN Y CARGA DE DATOS\n",
        "# ============================================================\n",
        "\n",
        "# Configuración MLflow (Ajustar URL si cambia ngrok)\n",
        "MLFLOW_URL = \"https://fleecier-rufus-decadently.ngrok-free.dev\"  \n",
        "mlflow.set_tracking_uri(MLFLOW_URL)\n",
        "mlflow.set_experiment(\"Exp5-Ablation_Scientific\")\n",
        "\n",
        "# Rutas de artefactos (Coherencia con Exp1)\n",
        "ARTIFACTS_DIR = \"artifacts_exp5\"\n",
        "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
        "\n",
        "# Cargar Datos\n",
        "npz_path = \"./data/intermediate/pixel_art_data.npz\"\n",
        "data = np.load(npz_path)\n",
        "images = data[\"images\"]  # (N,16,16,3) normalizado [0,1]\n",
        "\n",
        "# Convertir a Tensor\n",
        "images_tf = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "dataset_size = len(images)\n",
        "print(f\"Dataset cargado: {images.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. LÓGICA DE DIFUSIÓN (DDPM MATH)\n",
        "# ============================================================\n",
        "\n",
        "def make_beta_schedule(T, start=1e-4, end=2e-2):\n",
        "    \"\"\"Genera el schedule lineal de ruido.\"\"\"\n",
        "    betas = np.linspace(start, end, T, dtype=np.float32)\n",
        "    alphas = 1.0 - betas\n",
        "    alpha_cumprod = np.cumprod(alphas)\n",
        "    return betas, alphas, alpha_cumprod\n",
        "\n",
        "def extract(a, t, shape):\n",
        "    \"\"\"Extrae constantes para el paso t.\"\"\"\n",
        "    out = tf.gather(a, t)\n",
        "    return tf.reshape(out, (tf.shape(t)[0],) + (1,)*(len(shape)-1))\n",
        "\n",
        "def q_sample(x0, t, noise, sqrt_ac, sqrt_1mac):\n",
        "    \"\"\"Proceso Forward: Añadir ruido.\"\"\"\n",
        "    return extract(sqrt_ac, t, x0.shape) * x0 + \\\n",
        "           extract(sqrt_1mac, t, x0.shape) * noise\n",
        "\n",
        "# ============================================================\n",
        "# 3. MODELO U-NET (VARIABLE POR CAPACIDAD)\n",
        "# ============================================================\n",
        "\n",
        "def build_unet(base_channels=32, image_size=16):\n",
        "    \"\"\"\n",
        "    Construye una U-Net con capacidad variable.\n",
        "    CORRECCIÓN: Se usa layers.Lambda para el Time Embedding.\n",
        "    \"\"\"\n",
        "    def conv_block(x, channels):\n",
        "        x = layers.Conv2D(channels, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "        x = layers.Conv2D(channels, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    # --- Lógica de Embedding (Definida como función pura) ---\n",
        "    def sinusoidal_embedding_fn(t):\n",
        "        dim = 64  # Dimensión fija del embedding\n",
        "        half = dim // 2\n",
        "        # Frecuencias constantes\n",
        "        freqs = tf.exp(tf.range(half, dtype=tf.float32) * -np.log(10000.0)/(half-1))\n",
        "        # Cálculo de argumentos\n",
        "        args = tf.cast(t, tf.float32)[:, None] * freqs[None, :]\n",
        "        emb = tf.concat([tf.sin(args), tf.cos(args)], axis=-1)\n",
        "        # Padding si es impar\n",
        "        if dim % 2 == 1:\n",
        "            emb = tf.pad(emb, [[0,0],[0,1]])\n",
        "        return emb\n",
        "\n",
        "    # --- Entradas del Modelo ---\n",
        "    inp = layers.Input(shape=(image_size, image_size, 3), name=\"img_input\")\n",
        "    t_in = layers.Input(shape=(), dtype=tf.int32, name=\"time_input\")\n",
        "\n",
        "    # --- Aplicar Embedding usando Lambda Layer ---\n",
        "    # Esto soluciona el ValueError \"KerasTensor cannot be used as input to a TensorFlow function\"\n",
        "    t_emb = layers.Lambda(sinusoidal_embedding_fn, output_shape=(64,), name=\"time_embedding\")(t_in)\n",
        "    \n",
        "    # Procesar el embedding (Dense + Reshape)\n",
        "    t_emb = layers.Dense(128, activation=\"relu\")(t_emb)\n",
        "    t_emb = layers.Reshape((1,1,128))(t_emb)\n",
        "\n",
        "    # --- Encoder ---\n",
        "    c1 = conv_block(inp, base_channels)          # Level 1\n",
        "    x = layers.MaxPool2D()(c1)\n",
        "\n",
        "    c2 = conv_block(x, base_channels*2)          # Level 2\n",
        "    x = layers.MaxPool2D()(c2)\n",
        "\n",
        "    # --- Bottleneck ---\n",
        "    b = conv_block(x, base_channels*4)\n",
        "    \n",
        "    # Inyectar tiempo en el bottleneck (Concatenación)\n",
        "    # Nota: tf.tile también debe ser manejado con cuidado, pero usualmente Keras lo infiere.\n",
        "    # Si falla, usaremos una Lambda para el tile, pero probemos directo primero.\n",
        "    \n",
        "    # Opción segura para Tile usando Lambda también:\n",
        "    t_emb_tiled = layers.Lambda(lambda x: tf.tile(x, [1, 4, 4, 1]))(t_emb)\n",
        "    b = layers.Concatenate()([b, t_emb_tiled])\n",
        "\n",
        "    # --- Decoder ---\n",
        "    x = layers.UpSampling2D()(b)\n",
        "    x = layers.Concatenate()([x, c2])            # Skip Connection 2\n",
        "    x = conv_block(x, base_channels*2)\n",
        "\n",
        "    x = layers.UpSampling2D()(x)\n",
        "    x = layers.Concatenate()([x, c1])            # Skip Connection 1\n",
        "    x = conv_block(x, base_channels)\n",
        "\n",
        "    # Salida\n",
        "    out = layers.Conv2D(3, 1, padding=\"same\", name=\"prediction\")(x)\n",
        "\n",
        "    return Model([inp, t_in], out, name=f\"UNet_C{base_channels}\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. SAMPLING Y MÉTRICAS (Feature-FID)\n",
        "# ============================================================\n",
        "\n",
        "def sample_ddpm(model, T, betas, alphas, ac, num=64):\n",
        "    \"\"\"Genera muestras nuevas a partir de ruido puro.\"\"\"\n",
        "    z = tf.random.normal((num, 16, 16, 3))\n",
        "    \n",
        "    # Constantes en tensores para eficiencia\n",
        "    betas_tf = tf.constant(betas)\n",
        "    alphas_tf = tf.constant(alphas)\n",
        "    \n",
        "    for t in reversed(range(T)):\n",
        "        t_b = tf.fill((num,), t)\n",
        "        eps = model([z, t_b], training=False)\n",
        "\n",
        "        beta_t = betas_tf[t]\n",
        "        alpha_t = alphas_tf[t]\n",
        "        ac_t = ac[t]\n",
        "\n",
        "        # Ecuación de Reverse Diffusion\n",
        "        mean = (1 / tf.sqrt(alpha_t)) * (z - beta_t * eps / tf.sqrt(1 - ac_t))\n",
        "\n",
        "        if t > 0:\n",
        "            sigma_t = tf.sqrt(beta_t)\n",
        "            z = mean + sigma_t * tf.random.normal(tf.shape(z))\n",
        "        else:\n",
        "            z = mean\n",
        "\n",
        "    return tf.clip_by_value(z, 0, 1).numpy()\n",
        "\n",
        "def compute_feature_fid(real_imgs, gen_imgs, n_components=20):\n",
        "    \"\"\"\n",
        "    Calcula una distancia FID aproximada usando PCA (Feature-FID).\n",
        "    Más rápido que InceptionV3 para iteraciones científicas rápidas.\n",
        "    \"\"\"\n",
        "    # Aplanar imágenes\n",
        "    real_flat = real_imgs.reshape(len(real_imgs), -1)\n",
        "    gen_flat = gen_imgs.reshape(len(gen_imgs), -1)\n",
        "    \n",
        "    # Ajustar PCA sobre reales y transformar ambas\n",
        "    pca = PCA(n_components=n_components)\n",
        "    real_f = pca.fit_transform(real_flat)\n",
        "    gen_f = pca.transform(gen_flat) # Usar el mismo espacio latente\n",
        "\n",
        "    # Estadísticas\n",
        "    mu_real = real_f.mean(axis=0)\n",
        "    mu_gen  = gen_f.mean(axis=0)\n",
        "    cov_real = np.cov(real_f, rowvar=False)\n",
        "    cov_gen  = np.cov(gen_f, rowvar=False)\n",
        "\n",
        "    # Distancia de Fréchet (simplificada: traza + diff medias)\n",
        "    mean_dist = np.sum((mu_real - mu_gen)**2)\n",
        "    # Nota: La fórmula completa de FID usa sqrt(cov_real * cov_gen), \n",
        "    # pero para ablación relativa, la suma de diferencias cuadráticas de covarianza es un proxy aceptable.\n",
        "    cov_dist  = np.sum((cov_real - cov_gen)**2) \n",
        "\n",
        "    return float(mean_dist + cov_dist)\n",
        "\n",
        "# ============================================================\n",
        "# 5. CORE DE ABLACIÓN (TRAINING LOOP)\n",
        "# ============================================================\n",
        "\n",
        "def run_ablation_experiment(T_steps, base_channels, epochs=10, batch_size=128):\n",
        "    \"\"\"\n",
        "    Ejecuta un ciclo completo de entrenamiento y evaluación para una configuración dada.\n",
        "    \"\"\"\n",
        "    run_name = f\"DDPM_T{T_steps}_C{base_channels}\"\n",
        "    print(f\"\\n>>> INICIANDO RUN: {run_name} (Epochs={epochs})\")\n",
        "\n",
        "    # 1. Preparar Schedule\n",
        "    betas, alphas, ac = make_beta_schedule(T_steps)\n",
        "    sqrt_ac_tf = tf.constant(np.sqrt(ac), dtype=tf.float32)\n",
        "    sqrt_1mac_tf = tf.constant(np.sqrt(1-ac), dtype=tf.float32)\n",
        "\n",
        "    # 2. Construir Modelo y Optimizador\n",
        "    model = build_unet(base_channels=base_channels)\n",
        "    optimizer = optimizers.Adam(learning_rate=2e-4)\n",
        "    \n",
        "    # 3. Dataset Shuffling\n",
        "    ds = tf.data.Dataset.from_tensor_slices(images_tf)\n",
        "    ds = ds.shuffle(buffer_size=10000).batch(batch_size)\n",
        "\n",
        "    # 4. Iniciar MLflow Run\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        # Parametros\n",
        "        mlflow.log_param(\"T_steps\", T_steps)\n",
        "        mlflow.log_param(\"base_channels\", base_channels)\n",
        "        mlflow.log_param(\"epochs\", epochs)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"model_params\", model.count_params())\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # --- Training Loop Custom ---\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            epoch_losses = []\n",
        "            \n",
        "            for x0_batch in ds:\n",
        "                b_size = tf.shape(x0_batch)[0]\n",
        "                \n",
        "                # Muestrear t y ruido\n",
        "                t = tf.random.uniform((b_size,), 0, T_steps, dtype=tf.int32)\n",
        "                noise = tf.random.normal(tf.shape(x0_batch))\n",
        "                \n",
        "                # Forward diffussion\n",
        "                x_t = q_sample(x0_batch, t, noise, sqrt_ac_tf, sqrt_1mac_tf)\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    noise_pred = model([x_t, t], training=True)\n",
        "                    # Loss: MSE simple entre ruido real y predicho\n",
        "                    loss = tf.reduce_mean(tf.square(noise - noise_pred))\n",
        "                \n",
        "                grads = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "                epoch_losses.append(loss.numpy())\n",
        "\n",
        "            # Log metrics per epoch\n",
        "            avg_loss = np.mean(epoch_losses)\n",
        "            mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)\n",
        "            print(f\"   [Ep {epoch}/{epochs}] Loss: {avg_loss:.5f}\")\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        mlflow.log_metric(\"training_time_sec\", training_time)\n",
        "\n",
        "        # --- Evaluación y Generación ---\n",
        "        print(\"   > Generando muestras y calculando FID...\")\n",
        "        \n",
        "        # 1. Generar Muestras\n",
        "        generated_imgs = sample_ddpm(model, T_steps, betas, alphas, ac, num=64)\n",
        "        \n",
        "        # 2. Calcular FID-like (Usando subset real aleatorio)\n",
        "        idx_real = np.random.choice(len(images), size=min(1000, len(images)), replace=False)\n",
        "        real_subset = images[idx_real]\n",
        "        fid_score = compute_feature_fid(real_subset, generated_imgs)\n",
        "        mlflow.log_metric(\"feature_fid\", fid_score)\n",
        "        print(f\"   > Feature-FID: {fid_score:.4f}\")\n",
        "\n",
        "        # 3. Guardar Grid Visual\n",
        "        fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "        k = 0\n",
        "        for i in range(8):\n",
        "            for j in range(8):\n",
        "                axes[i, j].imshow(generated_imgs[k])\n",
        "                axes[i, j].axis(\"off\")\n",
        "                k += 1\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Guardar localmente\n",
        "        grid_filename = f\"samples_{run_name}.png\"\n",
        "        grid_path = os.path.join(ARTIFACTS_DIR, grid_filename)\n",
        "        plt.savefig(grid_path)\n",
        "        plt.close()\n",
        "        \n",
        "        # Guardar Modelo\n",
        "        model_filename = f\"model_{run_name}.keras\"\n",
        "        model_path = os.path.join(ARTIFACTS_DIR, model_filename)\n",
        "        model.save(model_path)\n",
        "\n",
        "        # 4. Loggear Artefactos a MLflow\n",
        "        mlflow.log_artifact(grid_path, r\"D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp5\")\n",
        "        mlflow.log_artifact(model_path, r\"D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp5\")\n",
        "        \n",
        "        print(f\"   >>> Run {run_name} finalizado.\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# 6. EJECUCIÓN DE LAS VARIANTES (A y B)\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # Configuración global\n",
        "    EPOCHS_PER_RUN = 15  # Aumentado un poco para notar diferencias\n",
        "    \n",
        "    print(\"=== INICIANDO EXPERIMENTO 5: ABLACIÓN ===\")\n",
        "\n",
        "    # --- VARIANTE A: Barrido de T (Pasos de difusión) ---\n",
        "    # Fijamos capacidad media (32) y variamos T\n",
        "    print(\"\\n--- VARIANTE A: Barrido de T ---\")\n",
        "    T_values = [50, 100, 200, 400]\n",
        "    fixed_capacity = 32\n",
        "    \n",
        "    for T in T_values:\n",
        "        run_ablation_experiment(T_steps=T, base_channels=fixed_capacity, epochs=EPOCHS_PER_RUN)\n",
        "\n",
        "    # --- VARIANTE B: Barrido de Capacidad ---\n",
        "    # Fijamos T razonable (200) y variamos canales\n",
        "    # Nota: Si ya corrimos T=200, C=32 en la variante A, podríamos saltarlo,\n",
        "    # pero para limpieza de los logs, lo volveremos a correr o lo filtramos.\n",
        "    print(\"\\n--- VARIANTE B: Barrido de Capacidad ---\")\n",
        "    C_values = [16, 64] # 32 ya se corrió arriba (T=200) típicamente\n",
        "    fixed_T = 200\n",
        "    \n",
        "    for C in C_values:\n",
        "        run_ablation_experiment(T_steps=fixed_T, base_channels=C, epochs=EPOCHS_PER_RUN)\n",
        "\n",
        "    print(\"=== TODOS LOS EXPERIMENTOS COMPLETADOS ===\")\n",
        "    print(f\"Revisar resultados en MLflow: {MLFLOW_URL}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
