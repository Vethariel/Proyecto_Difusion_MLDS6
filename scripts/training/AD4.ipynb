{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "YLOh1oDl8GDO",
        "outputId": "37462cbd-9d63-4e16-fbfb-1b5eac8aeb4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cargado: (89400, 16, 16, 3), Range: [0.0, 1.0]\n",
            "Cargando Autoencoder desde: D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp1\\autoencoder_model.keras ...\n",
            "Detectado Latent Layer: 'flatten' en Ã­ndice -7\n",
            "DimensiÃ³n Latente: 1024\n",
            "\n",
            "âœ“ Encoder: (None, 16, 16, 3) -> (None, 1024)\n",
            "âœ“ Decoder: (None, 1024) -> (None, 16, 16, 3)\n",
            "Check reconstrucciÃ³n shape: (1, 16, 16, 3)\n",
            "\n",
            "Generando representaciones latentes de todo el dataset...\n",
            "WARNING:tensorflow:5 out of the last 180 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018D90B62AC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m175/175\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Latentes normalizados. Mean ~ -0.00, Std ~ 0.95\n",
            "âœ“ Denoiser construido correctamente.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"denoiser_mlp\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"denoiser_mlp\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_t             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ time_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_t[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_z             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚ time_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_z[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> â”‚ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output_noise        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_t             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ time_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_t[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mLambda\u001b[0m)            â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_z             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚      \u001b[38;5;34m8,320\u001b[0m â”‚ time_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_z[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m590,336\u001b[0m â”‚ concatenate_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m262,656\u001b[0m â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚    \u001b[38;5;34m262,656\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output_noise        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,649,280</span> (6.29 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,649,280\u001b[0m (6.29 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,649,280</span> (6.29 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,649,280\u001b[0m (6.29 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100 - loss_latent: 0.793315\n",
            "Epoch 10/100 - loss_latent: 0.633866\n",
            "Epoch 20/100 - loss_latent: 0.628379\n",
            "Epoch 30/100 - loss_latent: 0.626005\n",
            "Epoch 40/100 - loss_latent: 0.624352\n",
            "Epoch 50/100 - loss_latent: 0.624283\n",
            "Epoch 60/100 - loss_latent: 0.623533\n",
            "Epoch 70/100 - loss_latent: 0.621799\n",
            "Epoch 80/100 - loss_latent: 0.621833\n",
            "Epoch 90/100 - loss_latent: 0.621482\n",
            "Epoch 100/100 - loss_latent: 0.620346\n",
            "Generando imÃ¡genes sintÃ©ticas...\n",
            "\n",
            "=== EXP4 FINALIZADO EXITOSAMENTE ===\n",
            "Artifacts guardados en 'artifacts_exp4' y registrados en MLflow.\n",
            "ğŸƒ View run Exp4-LatentDiffusion at: https://fleecier-rufus-decadently.ngrok-free.dev/#/experiments/4/runs/158876ba6a9943379beac92117161f5e\n",
            "ğŸ§ª View experiment at: https://fleecier-rufus-decadently.ngrok-free.dev/#/experiments/4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# EXPERIMENTO 4 â€” LATENT DIFFUSION MODEL (LDM-lite)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# ============================================================\n",
        "# 1. Config MLflow\n",
        "# ============================================================\n",
        "\n",
        "# AJUSTAR URL si cambiÃ³ tu tÃºnel de ngrok\n",
        "MLFLOW_URL = \"https://fleecier-rufus-decadently.ngrok-free.dev\"  \n",
        "mlflow.set_tracking_uri(MLFLOW_URL)\n",
        "mlflow.set_experiment(\"Exp4-LatentDiffusion\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. CARGAR DATASET\n",
        "# ============================================================\n",
        "\n",
        "npz_path = \"./data/intermediate/pixel_art_data.npz\"   # AJUSTAR RUTA SI ES NECESARIO\n",
        "data = np.load(npz_path)\n",
        "\n",
        "images = data[\"images\"]       # (N,16,16,3)\n",
        "# Asegurar normalizaciÃ³n correcta (0 a 1) para el Autoencoder\n",
        "if images.max() > 1.0:\n",
        "    images = images.astype(\"float32\") / 255.0\n",
        "\n",
        "print(f\"Dataset cargado: {images.shape}, Range: [{images.min()}, {images.max()}]\")\n",
        "images_tf = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "\n",
        "# ============================================================\n",
        "# 3. CARGAR AUTOENCODER (Del Exp 1)\n",
        "# ============================================================\n",
        "\n",
        "# Ruta al modelo guardado en el Experimento 1\n",
        "ae_path = r\"D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp1\\autoencoder_model.keras\"\n",
        "\n",
        "print(f\"Cargando Autoencoder desde: {ae_path} ...\")\n",
        "autoencoder = tf.keras.models.load_model(ae_path, compile=False)\n",
        "autoencoder.trainable = False  # Congelamos el AE, no se entrena aquÃ­\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.1. ExtracciÃ³n Coherente del Encoder (LÃ³gica Exp 1)\n",
        "# ------------------------------------------------------------\n",
        "# En Exp 1 usaste: autoencoder.layers[-7].output para los latentes.\n",
        "# Usamos exactamente la misma lÃ³gica para consistencia.\n",
        "\n",
        "latent_layer_idx = -7\n",
        "latent_layer = autoencoder.layers[latent_layer_idx]\n",
        "latent_dim = latent_layer.output.shape[-1]\n",
        "\n",
        "print(f\"Detectado Latent Layer: '{latent_layer.name}' en Ã­ndice {latent_layer_idx}\")\n",
        "print(f\"DimensiÃ³n Latente: {latent_dim}\")\n",
        "\n",
        "encoder = models.Model(\n",
        "    inputs=autoencoder.input,\n",
        "    outputs=latent_layer.output,\n",
        "    name=\"encoder_extracted\"\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.2. ReconstrucciÃ³n del Decoder\n",
        "# ------------------------------------------------------------\n",
        "# El decoder son todas las capas DESPUÃ‰S de la capa latente (-7).\n",
        "# Iteramos desde el Ã­ndice siguiente hasta el final.\n",
        "\n",
        "decoder_input = layers.Input(shape=(latent_dim,), name=\"decoder_input_z\")\n",
        "x = decoder_input\n",
        "\n",
        "# Ãndice real en la lista de capas (ej. si hay 20 capas, -7 es la 13, empezamos en la 14)\n",
        "start_idx = len(autoencoder.layers) + latent_layer_idx + 1\n",
        "\n",
        "for layer in autoencoder.layers[start_idx:]:\n",
        "    # Ojo: si hay capas de Reshape, hay que tener cuidado. \n",
        "    # Generalmente los AE simples funcionan bien asÃ­.\n",
        "    x = layer(x)\n",
        "\n",
        "decoder = models.Model(inputs=decoder_input, outputs=x, name=\"decoder_extracted\")\n",
        "\n",
        "print(f\"\\nâœ“ Encoder: {encoder.input_shape} -> {encoder.output_shape}\")\n",
        "print(f\"âœ“ Decoder: {decoder.input_shape} -> {decoder.output_shape}\")\n",
        "\n",
        "# ValidaciÃ³n rÃ¡pida\n",
        "test_z = encoder.predict(images[:1], verbose=0)\n",
        "test_rec = decoder.predict(test_z, verbose=0)\n",
        "print(f\"Check reconstrucciÃ³n shape: {test_rec.shape}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. PREPROCESAMIENTO LATENTE (CRÃTICO PARA DIFUSIÃ“N)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nGenerando representaciones latentes de todo el dataset...\")\n",
        "z_latents = encoder.predict(images, batch_size=512, verbose=1)\n",
        "\n",
        "# Aplanar si el latente no es plano (aunque layers[-7] suele ser Dense o Flatten)\n",
        "z_latents = z_latents.reshape((len(z_latents), -1))\n",
        "\n",
        "# --- ESTANDARIZACIÃ“N (Z-Score) ---\n",
        "# Los modelos de difusiÃ³n asumen ruido N(0,1). \n",
        "# Si el AE entrega valores en [0, 10] o [-100, 100], la difusiÃ³n fallarÃ¡.\n",
        "z_mean = np.mean(z_latents, axis=0)\n",
        "z_std = np.std(z_latents, axis=0) + 1e-6 # Evitar div por cero\n",
        "\n",
        "z_normalized = (z_latents - z_mean) / z_std\n",
        "\n",
        "print(f\"Latentes normalizados. Mean ~ {np.mean(z_normalized):.2f}, Std ~ {np.std(z_normalized):.2f}\")\n",
        "\n",
        "z_tf = tf.convert_to_tensor(z_normalized, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. DDPM SETTINGS (Espacio Latente)\n",
        "# ============================================================\n",
        "\n",
        "T = 200                  # Menos pasos que pÃ­xeles, el espacio es mÃ¡s simple\n",
        "LATENT_DIM_FLAT = z_tf.shape[1]\n",
        "BATCH_SIZE = 128         # Batch mÃ¡s grande porque z pesa poco\n",
        "EPOCHS = 100             # Se entrena muy rÃ¡pido, dale mÃ¡s Ã©pocas\n",
        "LR = 1e-3                # Learning rate un poco mÃ¡s agresivo para MLPs\n",
        "\n",
        "# Schedule de ruido lineal estÃ¡ndar\n",
        "beta_start = 1e-4\n",
        "beta_end   = 0.02\n",
        "betas = np.linspace(beta_start, beta_end, T, dtype=np.float32)\n",
        "\n",
        "alphas = 1.0 - betas\n",
        "alphas_cumprod = np.cumprod(alphas, axis=0)\n",
        "\n",
        "# Constantes para TF\n",
        "sqrt_alphas_cumprod_tf = tf.constant(np.sqrt(alphas_cumprod))\n",
        "sqrt_one_minus_alphas_cumprod_tf = tf.constant(np.sqrt(1 - alphas_cumprod))\n",
        "alphas_tf = tf.constant(alphas)\n",
        "betas_tf = tf.constant(betas)\n",
        "alphas_cumprod_tf = tf.constant(alphas_cumprod)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. FUNCIONES DDPM (Forward & Sampling)\n",
        "# ============================================================\n",
        "\n",
        "def extract(a, t, shape):\n",
        "    out = tf.gather(a, t)\n",
        "    return tf.reshape(out, (tf.shape(t)[0],) + (1,)*(len(shape)-1))\n",
        "\n",
        "def q_sample(z0, t, noise):\n",
        "    \"\"\"Forward diffusion: aÃ±adir ruido al latente z0\"\"\"\n",
        "    return extract(sqrt_alphas_cumprod_tf, t, z0.shape) * z0 + \\\n",
        "           extract(sqrt_one_minus_alphas_cumprod_tf, t, z0.shape) * noise\n",
        "\n",
        "# ============================================================\n",
        "# 7. MODELO DE DIFUSIÃ“N (MLP para Latentes) - CORREGIDO\n",
        "# ============================================================\n",
        "\n",
        "def build_latent_denoiser(dim):\n",
        "    inp_z = layers.Input(shape=(dim,), name=\"input_z\")\n",
        "    inp_t = layers.Input(shape=(), dtype=tf.int32, name=\"input_t\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # CORRECCIÃ“N: Definir la lÃ³gica dentro de una funciÃ³n pura\n",
        "    # ---------------------------------------------------------\n",
        "    def sinusoidal_embedding_fn(t_tensor):\n",
        "        embed_dim = 64\n",
        "        half = embed_dim // 2\n",
        "        \n",
        "        # MatemÃ¡ticas puras de TF\n",
        "        freqs = tf.exp(tf.range(half, dtype=tf.float32) * -np.log(10000.0) / (half - 1))\n",
        "        \n",
        "        # Casting seguro dentro de la funciÃ³n\n",
        "        t_cast = tf.cast(t_tensor, tf.float32)\n",
        "        \n",
        "        # Operaciones vectoriales\n",
        "        args = t_cast[:, None] * freqs[None, :]\n",
        "        emb = tf.concat([tf.sin(args), tf.cos(args)], axis=-1)\n",
        "        \n",
        "        # Padding si la dimensiÃ³n es impar\n",
        "        if embed_dim % 2 == 1:\n",
        "            emb = tf.pad(emb, [[0, 0], [0, 1]])\n",
        "            \n",
        "        return emb\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # CORRECCIÃ“N: Usar Lambda para conectar Keras con TF\n",
        "    # ---------------------------------------------------------\n",
        "    t_emb = layers.Lambda(sinusoidal_embedding_fn, output_shape=(64,), name=\"time_embedding\")(inp_t)\n",
        "\n",
        "    # A partir de aquÃ­, t_emb ya es un tensor procesado compatible con capas Keras\n",
        "    t_emb = layers.Dense(128, activation=\"swish\")(t_emb)\n",
        "\n",
        "    # Concatenar z y t\n",
        "    x = layers.Concatenate()([inp_z, t_emb])\n",
        "    \n",
        "    # Red Residual MLP simple\n",
        "    h1 = layers.Dense(512, activation=\"swish\")(x)\n",
        "    h2 = layers.Dense(512, activation=\"swish\")(h1)\n",
        "    h2 = layers.Add()([h1, h2]) # Skip connection\n",
        "    \n",
        "    h3 = layers.Dense(512, activation=\"swish\")(h2)\n",
        "    out = layers.Dense(dim, name=\"output_noise\")(h3)\n",
        "\n",
        "    return models.Model([inp_z, inp_t], out, name=\"denoiser_mlp\")\n",
        "\n",
        "# Volver a instanciar y compilar\n",
        "denoiser = build_latent_denoiser(LATENT_DIM_FLAT)\n",
        "optimizer = optimizers.Adam(LR)\n",
        "print(\"âœ“ Denoiser construido correctamente.\")\n",
        "print(denoiser.summary())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. TRAIN LOOP\n",
        "# ============================================================\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(z_tf)\n",
        "dataset = dataset.shuffle(10000).batch(BATCH_SIZE)\n",
        "\n",
        "@tf.function\n",
        "def train_step(z0):\n",
        "    bsz = tf.shape(z0)[0]\n",
        "    t = tf.random.uniform((bsz,), 0, T, dtype=tf.int32)\n",
        "    noise = tf.random.normal(tf.shape(z0))\n",
        "    \n",
        "    # Difundir en espacio latente\n",
        "    z_t = q_sample(z0, t, noise)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # El modelo intenta predecir el ruido aÃ±adido\n",
        "        noise_pred = denoiser([z_t, t], training=True)\n",
        "        loss = tf.reduce_mean(tf.square(noise - noise_pred))\n",
        "\n",
        "    grads = tape.gradient(loss, denoiser.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, denoiser.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. SAMPLING: Ruido -> Denoise -> Desnormalizar -> Decoder -> Imagen\n",
        "# ============================================================\n",
        "\n",
        "def sample_ldm(num_samples):\n",
        "    # 1. Empezar con ruido gaussiano puro\n",
        "    z = tf.random.normal((num_samples, LATENT_DIM_FLAT))\n",
        "\n",
        "    # 2. Iterar hacia atrÃ¡s T -> 0\n",
        "    for t in reversed(range(T)):\n",
        "        t_batch = tf.fill((num_samples,), t)\n",
        "        \n",
        "        # Predecir ruido\n",
        "        eps = denoiser([z, t_batch], training=False)\n",
        "\n",
        "        # Variables para la fÃ³rmula de muestreo\n",
        "        beta_t = extract(betas_tf, t_batch, z.shape)\n",
        "        alpha_t = extract(alphas_tf, t_batch, z.shape)\n",
        "        alpha_bar_t = extract(alphas_cumprod_tf, t_batch, z.shape)\n",
        "        \n",
        "        sigma_t = tf.sqrt(beta_t)\n",
        "\n",
        "        # EcuaciÃ³n de update (Langevin dynamics / DDPM)\n",
        "        mean = (1 / tf.sqrt(alpha_t)) * (z - (beta_t / tf.sqrt(1 - alpha_bar_t)) * eps)\n",
        "        \n",
        "        if t > 0:\n",
        "            noise = tf.random.normal(tf.shape(z))\n",
        "            z = mean + sigma_t * noise\n",
        "        else:\n",
        "            z = mean\n",
        "\n",
        "    # 3. IMPORTANTE: Des-estandarizar z (Volver al rango del Encoder original)\n",
        "    z_numpy = z.numpy()\n",
        "    z_denorm = (z_numpy * z_std) + z_mean\n",
        "    \n",
        "    # 4. Decodificar a pÃ­xeles\n",
        "    imgs = decoder.predict(z_denorm, verbose=0)\n",
        "    \n",
        "    # Clip para asegurar imagen vÃ¡lida\n",
        "    return np.clip(imgs, 0, 1)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 10. EJECUCIÃ“N CON MLFLOW\n",
        "# ============================================================\n",
        "\n",
        "with mlflow.start_run(run_name=\"Exp4-LatentDiffusion\"):\n",
        "\n",
        "    # Params\n",
        "    mlflow.log_param(\"T\", T)\n",
        "    mlflow.log_param(\"latent_dim\", LATENT_DIM_FLAT)\n",
        "    mlflow.log_param(\"epochs\", EPOCHS)\n",
        "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
        "    mlflow.log_param(\"learning_rate\", LR)\n",
        "\n",
        "    # Entrenar\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        losses = []\n",
        "        for batch in dataset:\n",
        "            loss = train_step(batch)\n",
        "            losses.append(loss.numpy())\n",
        "\n",
        "        mean_loss = float(np.mean(losses))\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(f\"Epoch {epoch}/{EPOCHS} - loss_latent: {mean_loss:.6f}\")\n",
        "        \n",
        "        mlflow.log_metric(\"loss\", mean_loss, step=epoch)\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 11. Generar Muestras Finales\n",
        "    # ------------------------------------------\n",
        "    print(\"Generando imÃ¡genes sintÃ©ticas...\")\n",
        "    samples = sample_ldm(64) # Generar 64 imÃ¡genes\n",
        "\n",
        "    # Guardar grid\n",
        "    fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "    k = 0\n",
        "    for i in range(8):\n",
        "        for j in range(8):\n",
        "            axes[i,j].imshow(samples[k])\n",
        "            axes[i,j].axis(\"off\")\n",
        "            k += 1\n",
        "    \n",
        "    os.makedirs(\"artifacts_exp4\", exist_ok=True)\n",
        "    grid_path = \"artifacts_exp4/ldm_generated_samples.png\"\n",
        "    plt.savefig(grid_path)\n",
        "    plt.close()\n",
        "    \n",
        "    # Log artifacts\n",
        "    mlflow.log_artifact(grid_path, r\"D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp4\")\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 12. Guardar Modelos y EstadÃ­sticas\n",
        "    # ------------------------------------------\n",
        "    # Necesitamos guardar denoiser Y las estadÃ­sticas (mean/std) para poder usarlo despuÃ©s\n",
        "    denoiser.save(\"artifacts_exp4/ldm_denoiser_model.keras\")\n",
        "    \n",
        "    # Guardar mean/std para inferencia futura\n",
        "    np.savez(\"artifacts_exp4/latent_stats.npz\", mean=z_mean, std=z_std)\n",
        "    \n",
        "    # Log a MLflow\n",
        "    mlflow.log_artifact(\"artifacts_exp4/ldm_denoiser_model.keras\", r\"D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp1\")\n",
        "    mlflow.log_artifact(\"artifacts_exp4/latent_stats.npz\", r\"D:\\documentos\\unal\\diplomados\\diplomado_ml_ds\\mod6_metodologias_agiles_desarrollo_proyectos_ml\\proyecto\\entrega_4_aux\\artifacts_exp1\")\n",
        "\n",
        "    print(\"\\n=== EXP4 FINALIZADO EXITOSAMENTE ===\")\n",
        "    print(f\"Artifacts guardados en 'artifacts_exp4' y registrados en MLflow.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
